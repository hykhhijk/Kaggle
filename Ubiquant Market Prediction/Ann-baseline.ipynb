{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e645fed",
   "metadata": {
    "papermill": {
     "duration": 0.013553,
     "end_time": "2022-03-30T13:31:43.996765",
     "exception": false,
     "start_time": "2022-03-30T13:31:43.983212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Baseline for Ubiquant Market Prediction using ANN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df32325",
   "metadata": {
    "papermill": {
     "duration": 0.015503,
     "end_time": "2022-03-30T13:31:44.032652",
     "exception": false,
     "start_time": "2022-03-30T13:31:44.017149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Thanks to notebook contributors for make baseline for my notebook**\n",
    "- https://www.kaggle.com/code/sohier/competition-api-detailed-introduction/notebook\n",
    "- https://www.kaggle.com/code/pythonash/end-to-end-simple-and-powerful-dnn-with-leakyrelu\n",
    "- https://www.kaggle.com/code/robikscube/fast-data-loading-and-low-mem-with-parquet-files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c84d1",
   "metadata": {
    "papermill": {
     "duration": 0.009485,
     "end_time": "2022-03-30T13:31:44.051944",
     "exception": false,
     "start_time": "2022-03-30T13:31:44.042459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "First import libraries and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6cd37d25",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T06:03:37.963630Z",
     "start_time": "2022-04-15T06:03:37.226238Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-03-30T13:31:44.081556Z",
     "iopub.status.busy": "2022-03-30T13:31:44.080942Z",
     "iopub.status.idle": "2022-03-30T13:31:51.961638Z",
     "shell.execute_reply": "2022-03-30T13:31:51.960466Z",
     "shell.execute_reply.started": "2022-03-30T12:46:06.43505Z"
    },
    "papermill": {
     "duration": 7.900134,
     "end_time": "2022-03-30T13:31:51.961783",
     "exception": false,
     "start_time": "2022-03-30T13:31:44.061649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05d993ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:14:54.575212Z",
     "start_time": "2022-04-14T13:14:16.439582Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:31:51.987891Z",
     "iopub.status.busy": "2022-03-30T13:31:51.987095Z",
     "iopub.status.idle": "2022-03-30T13:32:31.312242Z",
     "shell.execute_reply": "2022-03-30T13:32:31.311320Z",
     "shell.execute_reply.started": "2022-03-30T12:23:42.620177Z"
    },
    "papermill": {
     "duration": 39.340095,
     "end_time": "2022-03-30T13:32:31.312397",
     "exception": false,
     "start_time": "2022-03-30T13:31:51.972302",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_parquet('D:/kaggle_datasets/ubiquant-parquet/train_low_mem.parquet')\n",
    "df = df.astype(\"float16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17e3db75",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:14:55.935666Z",
     "start_time": "2022-04-14T13:14:55.921703Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d91f320",
   "metadata": {
    "papermill": {
     "duration": 0.009666,
     "end_time": "2022-03-30T13:32:31.332587",
     "exception": false,
     "start_time": "2022-03-30T13:32:31.322921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Preprocess dataset\n",
    "\n",
    "Because of it's baseline I use only f_n for features for X_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c72961c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:15:05.417556Z",
     "start_time": "2022-04-14T13:14:57.090945Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:32:34.337172Z",
     "iopub.status.busy": "2022-03-30T13:32:34.321467Z",
     "iopub.status.idle": "2022-03-30T13:32:41.679382Z",
     "shell.execute_reply": "2022-03-30T13:32:41.678908Z",
     "shell.execute_reply.started": "2022-03-30T12:24:10.683925Z"
    },
    "papermill": {
     "duration": 10.336824,
     "end_time": "2022-03-30T13:32:41.679509",
     "exception": false,
     "start_time": "2022-03-30T13:32:31.342685",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "index_col = df.drop([\"row_id\", \"time_id\", \"investment_id\", \"target\"], axis=1).columns\n",
    "X_train = df[index_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c9c5f6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:15:06.354383Z",
     "start_time": "2022-04-14T13:15:06.339633Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:32:41.704460Z",
     "iopub.status.busy": "2022-03-30T13:32:41.703344Z",
     "iopub.status.idle": "2022-03-30T13:32:41.705179Z",
     "shell.execute_reply": "2022-03-30T13:32:41.705565Z"
    },
    "papermill": {
     "duration": 0.016035,
     "end_time": "2022-03-30T13:32:41.705694",
     "exception": false,
     "start_time": "2022-03-30T13:32:41.689659",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train = df[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a8ada0",
   "metadata": {
    "papermill": {
     "duration": 0.011464,
     "end_time": "2022-03-30T13:32:41.727097",
     "exception": false,
     "start_time": "2022-03-30T13:32:41.715633",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Making model\n",
    "\n",
    "I make simple model using Dense layer and BatchNormalizaion without hyper parameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a58c4f51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:15:07.319051Z",
     "start_time": "2022-04-14T13:15:07.289841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2122479    900.0\n",
       "2122480    900.0\n",
       "2122481    900.0\n",
       "2122482    900.0\n",
       "2122483    900.0\n",
       "           ...  \n",
       "2125507    900.0\n",
       "2125508    900.0\n",
       "2125509    900.0\n",
       "2125510    900.0\n",
       "2125511    900.0\n",
       "Name: time_id, Length: 3033, dtype: float16"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"time_id\"][df[\"time_id\"]==900.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c4ad7702",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:15:08.317635Z",
     "start_time": "2022-04-14T13:15:08.303730Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = X_train[0:2122479], y_train[0:2122479], X_train[2122479:], y_train[2122479:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3813366d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T12:43:41.953391Z",
     "start_time": "2022-04-14T12:43:41.939438Z"
    }
   },
   "outputs": [],
   "source": [
    "def pearson_correlation(y_true, y_pred, axis=-1):\n",
    "    y_true = y_true-tf.reduce_mean(y_true)\n",
    "    y_pred = y_pred-tf.reduce_mean(y_pred)\n",
    "    y_true = tf.linalg.l2_normalize(y_true, axis=axis)\n",
    "    y_pred = tf.linalg.l2_normalize(y_pred, axis=axis)\n",
    "    return tf.reduce_sum(y_true * y_pred, axis=axis)\n",
    "\n",
    "def pearson_correlation_loss(y_true, y_pred, axis=-1):\n",
    "    y_true = y_true-tf.reduce_mean(y_true)\n",
    "    y_pred = y_pred-tf.reduce_mean(y_pred)\n",
    "    cosine = keras.losses.cosine_similarity(y_true, y_pred, axis=axis)\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15a0370f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:15:09.473626Z",
     "start_time": "2022-04-14T13:15:09.459747Z"
    }
   },
   "outputs": [],
   "source": [
    "es = keras.callbacks.EarlyStopping(monitor=\"val_mse\", patience=4, mode=\"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba65d498",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T13:15:12.841586Z",
     "start_time": "2022-04-14T13:15:10.613860Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:32:41.753747Z",
     "iopub.status.busy": "2022-03-30T13:32:41.753248Z",
     "iopub.status.idle": "2022-03-30T13:32:45.722742Z",
     "shell.execute_reply": "2022-03-30T13:32:45.723351Z"
    },
    "papermill": {
     "duration": 3.986594,
     "end_time": "2022-03-30T13:32:45.723539",
     "exception": false,
     "start_time": "2022-03-30T13:32:41.736945",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(128, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ff81b20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:32:13.773095Z",
     "start_time": "2022-04-14T13:15:13.938860Z"
    },
    "execution": {
     "iopub.execute_input": "2022-03-30T13:32:45.751718Z",
     "iopub.status.busy": "2022-03-30T13:32:45.750965Z",
     "iopub.status.idle": "2022-03-30T14:05:48.148745Z",
     "shell.execute_reply": "2022-03-30T14:05:48.148314Z"
    },
    "papermill": {
     "duration": 1982.413617,
     "end_time": "2022-03-30T14:05:48.148882",
     "exception": false,
     "start_time": "2022-03-30T13:32:45.735265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "66328/66328 [==============================] - 653s 10ms/step - loss: 0.8357 - mse: 0.8357 - mae: 0.6334 - val_loss: 0.8317 - val_mse: 0.8317 - val_mae: 0.6098\n",
      "Epoch 2/15\n",
      "66328/66328 [==============================] - 691s 10ms/step - loss: 0.8289 - mse: 0.8289 - mae: 0.6305 - val_loss: 0.8324 - val_mse: 0.8324 - val_mae: 0.6108\n",
      "Epoch 3/15\n",
      "66328/66328 [==============================] - 687s 10ms/step - loss: 0.8259 - mse: 0.8259 - mae: 0.6294 - val_loss: 0.8309 - val_mse: 0.8309 - val_mae: 0.6103\n",
      "Epoch 4/15\n",
      "66328/66328 [==============================] - 693s 10ms/step - loss: 0.8235 - mse: 0.8235 - mae: 0.6285 - val_loss: 0.8321 - val_mse: 0.8321 - val_mae: 0.6116\n",
      "Epoch 5/15\n",
      "66328/66328 [==============================] - 626s 9ms/step - loss: 0.8214 - mse: 0.8214 - mae: 0.6277 - val_loss: 0.8334 - val_mse: 0.8334 - val_mae: 0.6143\n",
      "Epoch 6/15\n",
      "66328/66328 [==============================] - 660s 10ms/step - loss: 0.8194 - mse: 0.8194 - mae: 0.6271 - val_loss: 0.8311 - val_mse: 0.8311 - val_mae: 0.6117\n",
      "Epoch 7/15\n",
      "66328/66328 [==============================] - 608s 9ms/step - loss: 0.8176 - mse: 0.8176 - mae: 0.6264 - val_loss: 0.8373 - val_mse: 0.8373 - val_mae: 0.6135\n"
     ]
    }
   ],
   "source": [
    "history=[]\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\", \"mae\"])\n",
    "history.append(model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, callbacks=[es]))\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ff6a9585",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T14:32:14.972082Z",
     "start_time": "2022-04-14T14:32:14.831105Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(256, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16, activation=\"relu\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ede6e16f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:34:37.045260Z",
     "start_time": "2022-04-14T14:32:15.874937Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "66328/66328 [==============================] - 743s 11ms/step - loss: 0.8383 - mse: 0.8383 - mae: 0.6346 - val_loss: 0.8281 - val_mse: 0.8281 - val_mae: 0.6087\n",
      "Epoch 2/15\n",
      "66328/66328 [==============================] - 749s 11ms/step - loss: 0.8305 - mse: 0.8305 - mae: 0.6312 - val_loss: 0.8328 - val_mse: 0.8328 - val_mae: 0.6120\n",
      "Epoch 3/15\n",
      "66328/66328 [==============================] - 748s 11ms/step - loss: 0.8276 - mse: 0.8276 - mae: 0.6300 - val_loss: 0.8296 - val_mse: 0.8296 - val_mae: 0.6130\n",
      "Epoch 4/15\n",
      "66328/66328 [==============================] - 749s 11ms/step - loss: 0.8250 - mse: 0.8250 - mae: 0.6291 - val_loss: 0.8306 - val_mse: 0.8306 - val_mae: 0.6110\n",
      "Epoch 5/15\n",
      "66328/66328 [==============================] - 749s 11ms/step - loss: 0.8225 - mse: 0.8225 - mae: 0.6282 - val_loss: 0.8348 - val_mse: 0.8348 - val_mae: 0.6137\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\", \"mae\"])\n",
    "history.append(model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, callbacks=[es]))\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a84416cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T15:34:38.014829Z",
     "start_time": "2022-04-14T15:34:37.921567Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(128, activation=\"swish\", kernel_initializer=keras.initializers.he_normal)(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"swish\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32, activation=\"swish\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16, activation=\"swish\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\", kernel_initializer=keras.initializers.he_normal)(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b66cb5cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T16:30:55.756289Z",
     "start_time": "2022-04-14T15:34:38.857930Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "66328/66328 [==============================] - 655s 10ms/step - loss: 0.8349 - mse: 0.8349 - mae: 0.6330 - val_loss: 0.8288 - val_mse: 0.8288 - val_mae: 0.6102\n",
      "Epoch 2/15\n",
      "66328/66328 [==============================] - 660s 10ms/step - loss: 0.8286 - mse: 0.8286 - mae: 0.6303 - val_loss: 0.8333 - val_mse: 0.8333 - val_mae: 0.6134\n",
      "Epoch 3/15\n",
      "66328/66328 [==============================] - 665s 10ms/step - loss: 0.8260 - mse: 0.8260 - mae: 0.6293 - val_loss: 0.8329 - val_mse: 0.8329 - val_mae: 0.6121\n",
      "Epoch 4/15\n",
      "66328/66328 [==============================] - 692s 10ms/step - loss: 0.8236 - mse: 0.8236 - mae: 0.6285 - val_loss: 0.8341 - val_mse: 0.8341 - val_mae: 0.6151\n",
      "Epoch 5/15\n",
      "66328/66328 [==============================] - 702s 11ms/step - loss: 0.8214 - mse: 0.8214 - mae: 0.6276 - val_loss: 0.8350 - val_mse: 0.8350 - val_mae: 0.6127\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\", \"mae\"])\n",
    "history.append(model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=15, callbacks=[es]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0f9d816a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-15T06:07:33.819114Z",
     "start_time": "2022-04-15T06:07:33.561781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history[0].history[\"val_mse\"], label=\"relu\")\n",
    "plt.plot(history[2].history[\"val_mse\"], label=\"swish\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4f41ca1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T08:56:55.079841Z",
     "start_time": "2022-04-14T08:56:54.983090Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(128)(Input)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2, )(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model_leak = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dff0b91",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-14T09:41:02.945294Z",
     "start_time": "2022-04-14T08:56:55.830582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "53062/53062 [==============================] - 535s 10ms/step - loss: -0.0168 - mse: 5.1480 - pearson_correlation: 0.0168 - val_loss: -0.0261 - val_mse: 5.6028 - val_pearson_correlation: 0.0261\n",
      "Epoch 2/5\n",
      "53062/53062 [==============================] - 537s 10ms/step - loss: -0.0410 - mse: 9.0370 - pearson_correlation: 0.0410 - val_loss: -0.0213 - val_mse: 12.6602 - val_pearson_correlation: 0.0213\n",
      "Epoch 3/5\n",
      "53062/53062 [==============================] - 547s 10ms/step - loss: -0.0387 - mse: 12.3854 - pearson_correlation: 0.0387 - val_loss: -0.0224 - val_mse: 12.7966 - val_pearson_correlation: 0.0224\n",
      "Epoch 4/5\n",
      "53062/53062 [==============================] - 515s 10ms/step - loss: -0.0497 - mse: 15.0104 - pearson_correlation: 0.0497 - val_loss: -0.0341 - val_mse: 18.8002 - val_pearson_correlation: 0.0341\n",
      "Epoch 5/5\n",
      "53062/53062 [==============================] - 511s 10ms/step - loss: -0.0675 - mse: 20.9339 - pearson_correlation: 0.0675 - val_loss: -0.0520 - val_mse: 47.9651 - val_pearson_correlation: 0.0520\n"
     ]
    }
   ],
   "source": [
    "model_leak.compile(loss=pearson_correlation_loss, optimizer=\"adam\", metrics=[\"mse\", pearson_correlation])\n",
    "history = model_leak.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86a1cd",
   "metadata": {},
   "source": [
    "# 특성 공학 및 하이퍼 파라미터 서칭 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b45bce74",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T06:39:34.671084Z",
     "start_time": "2022-04-07T06:39:34.480488Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(128)(Input)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16)(x)\n",
    "x = keras.layers.LeakyReLU(alpha=0.2, )(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model_leak = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9f4f3ce2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-05T15:23:30.602843Z",
     "start_time": "2022-04-05T14:49:56.176370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2513128 samples, validate on 628282 samples\n",
      "Epoch 1/5\n",
      "2513128/2513128 [==============================] - 469s 187us/sample - loss: 0.8408 - mse: 0.8408 - val_loss: 0.8120 - val_mse: 0.8120\n",
      "Epoch 2/5\n",
      "2513128/2513128 [==============================] - 421s 167us/sample - loss: 0.8347 - mse: 0.8347 - val_loss: 0.8096 - val_mse: 0.8096\n",
      "Epoch 3/5\n",
      "2513128/2513128 [==============================] - 427s 170us/sample - loss: 0.8323 - mse: 0.8323 - val_loss: 0.8087 - val_mse: 0.8087\n",
      "Epoch 4/5\n",
      "2513128/2513128 [==============================] - 347s 138us/sample - loss: 0.8308 - mse: 0.8308 - val_loss: 0.8127 - val_mse: 0.8127\n",
      "Epoch 5/5\n",
      "2513128/2513128 [==============================] - 347s 138us/sample - loss: 0.8296 - mse: 0.8296 - val_loss: 0.8107 - val_mse: 0.8107\n"
     ]
    }
   ],
   "source": [
    "model_leak.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mse\"])\n",
    "history = model_leak.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02abbd8b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:04:32.039388Z",
     "start_time": "2022-04-08T06:04:18.552655Z"
    }
   },
   "outputs": [],
   "source": [
    "index_col = df.drop([\"row_id\", \"target\", \"time_id\"], axis=1).columns\n",
    "X_train = df[index_col]\n",
    "X_train = X_train.astype(\"float16\")\n",
    "y_train = df[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1eff013b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:04:40.363837Z",
     "start_time": "2022-04-08T06:04:39.987069Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>investment_id</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>f_7</th>\n",
       "      <th>f_8</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932617</td>\n",
       "      <td>0.113708</td>\n",
       "      <td>-0.402100</td>\n",
       "      <td>0.378418</td>\n",
       "      <td>-0.203979</td>\n",
       "      <td>-0.413574</td>\n",
       "      <td>0.965820</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.365967</td>\n",
       "      <td>-1.095703</td>\n",
       "      <td>0.200073</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.086792</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-1.044922</td>\n",
       "      <td>-0.287598</td>\n",
       "      <td>0.321533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.811035</td>\n",
       "      <td>-0.514160</td>\n",
       "      <td>0.742188</td>\n",
       "      <td>-0.616699</td>\n",
       "      <td>-0.194214</td>\n",
       "      <td>1.771484</td>\n",
       "      <td>1.427734</td>\n",
       "      <td>1.133789</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154175</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.734375</td>\n",
       "      <td>0.819336</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.387695</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-0.929688</td>\n",
       "      <td>-0.974121</td>\n",
       "      <td>-0.343506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.394043</td>\n",
       "      <td>0.615723</td>\n",
       "      <td>0.567871</td>\n",
       "      <td>-0.607910</td>\n",
       "      <td>0.068909</td>\n",
       "      <td>-1.083008</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>-1.125977</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138062</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.551758</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>-1.060547</td>\n",
       "      <td>-0.219116</td>\n",
       "      <td>-1.086914</td>\n",
       "      <td>-0.612305</td>\n",
       "      <td>-0.113953</td>\n",
       "      <td>0.243652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-2.343750</td>\n",
       "      <td>-0.011871</td>\n",
       "      <td>1.875000</td>\n",
       "      <td>-0.606445</td>\n",
       "      <td>-0.586914</td>\n",
       "      <td>-0.815918</td>\n",
       "      <td>0.778320</td>\n",
       "      <td>0.299072</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382080</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.266357</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.608887</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>-0.783203</td>\n",
       "      <td>1.151367</td>\n",
       "      <td>-0.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.842285</td>\n",
       "      <td>-0.262939</td>\n",
       "      <td>2.330078</td>\n",
       "      <td>-0.583496</td>\n",
       "      <td>-0.618164</td>\n",
       "      <td>-0.742676</td>\n",
       "      <td>-0.946777</td>\n",
       "      <td>1.230469</td>\n",
       "      <td>0.114807</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170410</td>\n",
       "      <td>0.912598</td>\n",
       "      <td>-0.741211</td>\n",
       "      <td>-1.220703</td>\n",
       "      <td>0.941406</td>\n",
       "      <td>-0.588379</td>\n",
       "      <td>0.104919</td>\n",
       "      <td>0.753418</td>\n",
       "      <td>1.345703</td>\n",
       "      <td>-0.737793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141405</th>\n",
       "      <td>3768.0</td>\n",
       "      <td>0.093506</td>\n",
       "      <td>-0.720215</td>\n",
       "      <td>-0.345459</td>\n",
       "      <td>-0.438721</td>\n",
       "      <td>-0.166992</td>\n",
       "      <td>-0.437256</td>\n",
       "      <td>1.475586</td>\n",
       "      <td>1.284180</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285889</td>\n",
       "      <td>-1.232422</td>\n",
       "      <td>-0.660645</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.427979</td>\n",
       "      <td>-0.075562</td>\n",
       "      <td>-0.533203</td>\n",
       "      <td>-0.193726</td>\n",
       "      <td>-0.581543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141406</th>\n",
       "      <td>3768.0</td>\n",
       "      <td>-1.344727</td>\n",
       "      <td>-0.199951</td>\n",
       "      <td>-0.107727</td>\n",
       "      <td>-0.454590</td>\n",
       "      <td>-0.221924</td>\n",
       "      <td>-0.141113</td>\n",
       "      <td>-1.498047</td>\n",
       "      <td>1.374023</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184570</td>\n",
       "      <td>-1.232422</td>\n",
       "      <td>-0.670410</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.729980</td>\n",
       "      <td>-1.514648</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>-0.890137</td>\n",
       "      <td>-0.589844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141407</th>\n",
       "      <td>3770.0</td>\n",
       "      <td>0.979492</td>\n",
       "      <td>-1.110352</td>\n",
       "      <td>1.006836</td>\n",
       "      <td>-0.467285</td>\n",
       "      <td>-0.159546</td>\n",
       "      <td>1.355469</td>\n",
       "      <td>0.150757</td>\n",
       "      <td>-0.088928</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756348</td>\n",
       "      <td>-1.232422</td>\n",
       "      <td>0.820801</td>\n",
       "      <td>-1.142578</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.363281</td>\n",
       "      <td>1.363281</td>\n",
       "      <td>-0.079102</td>\n",
       "      <td>-1.580078</td>\n",
       "      <td>-0.297607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141408</th>\n",
       "      <td>3772.0</td>\n",
       "      <td>-2.564453</td>\n",
       "      <td>0.320312</td>\n",
       "      <td>0.076599</td>\n",
       "      <td>1.379883</td>\n",
       "      <td>-0.155396</td>\n",
       "      <td>-0.688965</td>\n",
       "      <td>0.381104</td>\n",
       "      <td>-1.325195</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756348</td>\n",
       "      <td>-1.232422</td>\n",
       "      <td>0.133057</td>\n",
       "      <td>-1.142578</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.375244</td>\n",
       "      <td>-1.514648</td>\n",
       "      <td>-0.973633</td>\n",
       "      <td>0.608887</td>\n",
       "      <td>-0.372070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141409</th>\n",
       "      <td>3772.0</td>\n",
       "      <td>-0.089539</td>\n",
       "      <td>0.190186</td>\n",
       "      <td>-0.548340</td>\n",
       "      <td>0.151245</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>0.447998</td>\n",
       "      <td>1.014648</td>\n",
       "      <td>-1.325195</td>\n",
       "      <td>0.056427</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317139</td>\n",
       "      <td>0.811523</td>\n",
       "      <td>3.271484</td>\n",
       "      <td>0.875488</td>\n",
       "      <td>0.421631</td>\n",
       "      <td>-0.170654</td>\n",
       "      <td>1.363281</td>\n",
       "      <td>-0.563477</td>\n",
       "      <td>0.669434</td>\n",
       "      <td>0.456299</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3141410 rows × 301 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         investment_id       f_0       f_1       f_2       f_3       f_4  \\\n",
       "0                  1.0  0.932617  0.113708 -0.402100  0.378418 -0.203979   \n",
       "1                  2.0  0.811035 -0.514160  0.742188 -0.616699 -0.194214   \n",
       "2                  6.0  0.394043  0.615723  0.567871 -0.607910  0.068909   \n",
       "3                  7.0 -2.343750 -0.011871  1.875000 -0.606445 -0.586914   \n",
       "4                  8.0  0.842285 -0.262939  2.330078 -0.583496 -0.618164   \n",
       "...                ...       ...       ...       ...       ...       ...   \n",
       "3141405         3768.0  0.093506 -0.720215 -0.345459 -0.438721 -0.166992   \n",
       "3141406         3768.0 -1.344727 -0.199951 -0.107727 -0.454590 -0.221924   \n",
       "3141407         3770.0  0.979492 -1.110352  1.006836 -0.467285 -0.159546   \n",
       "3141408         3772.0 -2.564453  0.320312  0.076599  1.379883 -0.155396   \n",
       "3141409         3772.0 -0.089539  0.190186 -0.548340  0.151245  0.079773   \n",
       "\n",
       "              f_5       f_6       f_7       f_8  ...     f_290     f_291  \\\n",
       "0       -0.413574  0.965820  1.230469  0.114807  ...  0.365967 -1.095703   \n",
       "1        1.771484  1.427734  1.133789  0.114807  ... -0.154175  0.912598   \n",
       "2       -1.083008  0.979492 -1.125977  0.114807  ... -0.138062  0.912598   \n",
       "3       -0.815918  0.778320  0.299072  0.114807  ...  0.382080  0.912598   \n",
       "4       -0.742676 -0.946777  1.230469  0.114807  ... -0.170410  0.912598   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "3141405 -0.437256  1.475586  1.284180  0.056427  ... -0.285889 -1.232422   \n",
       "3141406 -0.141113 -1.498047  1.374023  0.056427  ...  0.184570 -1.232422   \n",
       "3141407  1.355469  0.150757 -0.088928  0.056427  ... -0.756348 -1.232422   \n",
       "3141408 -0.688965  0.381104 -1.325195  0.056427  ... -0.756348 -1.232422   \n",
       "3141409  0.447998  1.014648 -1.325195  0.056427  ... -0.317139  0.811523   \n",
       "\n",
       "            f_292     f_293     f_294     f_295     f_296     f_297     f_298  \\\n",
       "0        0.200073  0.819336  0.941406 -0.086792 -1.086914 -1.044922 -0.287598   \n",
       "1       -0.734375  0.819336  0.941406 -0.387695 -1.086914 -0.929688 -0.974121   \n",
       "2       -0.551758 -1.220703 -1.060547 -0.219116 -1.086914 -0.612305 -0.113953   \n",
       "3       -0.266357 -1.220703  0.941406 -0.608887  0.104919 -0.783203  1.151367   \n",
       "4       -0.741211 -1.220703  0.941406 -0.588379  0.104919  0.753418  1.345703   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3141405 -0.660645  0.875488  0.421631 -0.427979 -0.075562 -0.533203 -0.193726   \n",
       "3141406 -0.670410  0.875488  0.421631 -0.729980 -1.514648  0.013145 -0.890137   \n",
       "3141407  0.820801 -1.142578  0.421631 -0.363281  1.363281 -0.079102 -1.580078   \n",
       "3141408  0.133057 -1.142578  0.421631 -0.375244 -1.514648 -0.973633  0.608887   \n",
       "3141409  3.271484  0.875488  0.421631 -0.170654  1.363281 -0.563477  0.669434   \n",
       "\n",
       "            f_299  \n",
       "0        0.321533  \n",
       "1       -0.343506  \n",
       "2        0.243652  \n",
       "3       -0.773438  \n",
       "4       -0.737793  \n",
       "...           ...  \n",
       "3141405 -0.581543  \n",
       "3141406 -0.589844  \n",
       "3141407 -0.297607  \n",
       "3141408 -0.372070  \n",
       "3141409  0.456299  \n",
       "\n",
       "[3141410 rows x 301 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "82d5f849",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-08T06:04:55.840910Z",
     "start_time": "2022-04-08T06:04:55.136223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>row_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0_1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.300875</td>\n",
       "      <td>0.932573</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>-0.402206</td>\n",
       "      <td>0.378386</td>\n",
       "      <td>-0.203938</td>\n",
       "      <td>-0.413469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366028</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>0.200075</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.086764</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-1.044826</td>\n",
       "      <td>-0.287605</td>\n",
       "      <td>0.321566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.231040</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>-0.514115</td>\n",
       "      <td>0.742368</td>\n",
       "      <td>-0.616673</td>\n",
       "      <td>-0.194255</td>\n",
       "      <td>1.771210</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154193</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.734579</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.387617</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.929529</td>\n",
       "      <td>-0.974060</td>\n",
       "      <td>-0.343624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0_6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.568807</td>\n",
       "      <td>0.393974</td>\n",
       "      <td>0.615937</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>-0.607963</td>\n",
       "      <td>0.068883</td>\n",
       "      <td>-1.083155</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138020</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.551904</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>-1.060166</td>\n",
       "      <td>-0.219097</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.612428</td>\n",
       "      <td>-0.113944</td>\n",
       "      <td>0.243608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0_7</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>-1.064780</td>\n",
       "      <td>-2.343535</td>\n",
       "      <td>-0.011870</td>\n",
       "      <td>1.874606</td>\n",
       "      <td>-0.606346</td>\n",
       "      <td>-0.586827</td>\n",
       "      <td>-0.815737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382201</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.266359</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.609113</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>-0.783423</td>\n",
       "      <td>1.151730</td>\n",
       "      <td>-0.773309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0_8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.531940</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>-0.262993</td>\n",
       "      <td>2.330030</td>\n",
       "      <td>-0.583422</td>\n",
       "      <td>-0.618392</td>\n",
       "      <td>-0.742814</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170365</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.588445</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>0.753279</td>\n",
       "      <td>1.345611</td>\n",
       "      <td>-0.737624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141405</th>\n",
       "      <td>1219_3768</td>\n",
       "      <td>1219</td>\n",
       "      <td>3768</td>\n",
       "      <td>0.033600</td>\n",
       "      <td>0.093530</td>\n",
       "      <td>-0.720275</td>\n",
       "      <td>-0.345497</td>\n",
       "      <td>-0.438781</td>\n",
       "      <td>-0.166972</td>\n",
       "      <td>-0.437182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.285908</td>\n",
       "      <td>-1.232434</td>\n",
       "      <td>-0.660579</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.428097</td>\n",
       "      <td>-0.075548</td>\n",
       "      <td>-0.533092</td>\n",
       "      <td>-0.193732</td>\n",
       "      <td>-0.581394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141406</th>\n",
       "      <td>1219_3769</td>\n",
       "      <td>1219</td>\n",
       "      <td>3769</td>\n",
       "      <td>-0.223264</td>\n",
       "      <td>-1.344935</td>\n",
       "      <td>-0.199987</td>\n",
       "      <td>-0.107702</td>\n",
       "      <td>-0.454677</td>\n",
       "      <td>-0.221914</td>\n",
       "      <td>-0.141174</td>\n",
       "      <td>...</td>\n",
       "      <td>0.184517</td>\n",
       "      <td>-1.232434</td>\n",
       "      <td>-0.670493</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.729949</td>\n",
       "      <td>-1.514277</td>\n",
       "      <td>0.013145</td>\n",
       "      <td>-0.890270</td>\n",
       "      <td>-0.589705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141407</th>\n",
       "      <td>1219_3770</td>\n",
       "      <td>1219</td>\n",
       "      <td>3770</td>\n",
       "      <td>-0.559415</td>\n",
       "      <td>0.979489</td>\n",
       "      <td>-1.110491</td>\n",
       "      <td>1.006980</td>\n",
       "      <td>-0.467307</td>\n",
       "      <td>-0.159549</td>\n",
       "      <td>1.355671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756332</td>\n",
       "      <td>-1.232434</td>\n",
       "      <td>0.820784</td>\n",
       "      <td>-1.142157</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.363329</td>\n",
       "      <td>1.363181</td>\n",
       "      <td>-0.079106</td>\n",
       "      <td>-1.580124</td>\n",
       "      <td>-0.297625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141408</th>\n",
       "      <td>1219_3772</td>\n",
       "      <td>1219</td>\n",
       "      <td>3772</td>\n",
       "      <td>0.009599</td>\n",
       "      <td>-2.565332</td>\n",
       "      <td>0.320301</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>1.380182</td>\n",
       "      <td>-0.155366</td>\n",
       "      <td>-0.689000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.756332</td>\n",
       "      <td>-1.232434</td>\n",
       "      <td>0.133074</td>\n",
       "      <td>-1.142157</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.375288</td>\n",
       "      <td>-1.514277</td>\n",
       "      <td>-0.973762</td>\n",
       "      <td>0.608647</td>\n",
       "      <td>-0.372040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3141409</th>\n",
       "      <td>1219_3773</td>\n",
       "      <td>1219</td>\n",
       "      <td>3773</td>\n",
       "      <td>1.212112</td>\n",
       "      <td>-0.089557</td>\n",
       "      <td>0.190229</td>\n",
       "      <td>-0.548256</td>\n",
       "      <td>0.151205</td>\n",
       "      <td>0.079773</td>\n",
       "      <td>0.447962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.317095</td>\n",
       "      <td>0.811402</td>\n",
       "      <td>3.271590</td>\n",
       "      <td>0.875537</td>\n",
       "      <td>0.421628</td>\n",
       "      <td>-0.170709</td>\n",
       "      <td>1.363181</td>\n",
       "      <td>-0.563314</td>\n",
       "      <td>0.669586</td>\n",
       "      <td>0.456400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3141410 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            row_id  time_id  investment_id    target       f_0       f_1  \\\n",
       "0              0_1        0              1 -0.300875  0.932573  0.113691   \n",
       "1              0_2        0              2 -0.231040  0.810802 -0.514115   \n",
       "2              0_6        0              6  0.568807  0.393974  0.615937   \n",
       "3              0_7        0              7 -1.064780 -2.343535 -0.011870   \n",
       "4              0_8        0              8 -0.531940  0.842057 -0.262993   \n",
       "...            ...      ...            ...       ...       ...       ...   \n",
       "3141405  1219_3768     1219           3768  0.033600  0.093530 -0.720275   \n",
       "3141406  1219_3769     1219           3769 -0.223264 -1.344935 -0.199987   \n",
       "3141407  1219_3770     1219           3770 -0.559415  0.979489 -1.110491   \n",
       "3141408  1219_3772     1219           3772  0.009599 -2.565332  0.320301   \n",
       "3141409  1219_3773     1219           3773  1.212112 -0.089557  0.190229   \n",
       "\n",
       "              f_2       f_3       f_4       f_5  ...     f_290     f_291  \\\n",
       "0       -0.402206  0.378386 -0.203938 -0.413469  ...  0.366028 -1.095620   \n",
       "1        0.742368 -0.616673 -0.194255  1.771210  ... -0.154193  0.912726   \n",
       "2        0.567806 -0.607963  0.068883 -1.083155  ... -0.138020  0.912726   \n",
       "3        1.874606 -0.606346 -0.586827 -0.815737  ...  0.382201  0.912726   \n",
       "4        2.330030 -0.583422 -0.618392 -0.742814  ... -0.170365  0.912726   \n",
       "...           ...       ...       ...       ...  ...       ...       ...   \n",
       "3141405 -0.345497 -0.438781 -0.166972 -0.437182  ... -0.285908 -1.232434   \n",
       "3141406 -0.107702 -0.454677 -0.221914 -0.141174  ...  0.184517 -1.232434   \n",
       "3141407  1.006980 -0.467307 -0.159549  1.355671  ... -0.756332 -1.232434   \n",
       "3141408  0.076600  1.380182 -0.155366 -0.689000  ... -0.756332 -1.232434   \n",
       "3141409 -0.548256  0.151205  0.079773  0.447962  ... -0.317095  0.811402   \n",
       "\n",
       "            f_292     f_293     f_294     f_295     f_296     f_297     f_298  \\\n",
       "0        0.200075  0.819155  0.941183 -0.086764 -1.087009 -1.044826 -0.287605   \n",
       "1       -0.734579  0.819155  0.941183 -0.387617 -1.087009 -0.929529 -0.974060   \n",
       "2       -0.551904 -1.220772 -1.060166 -0.219097 -1.087009 -0.612428 -0.113944   \n",
       "3       -0.266359 -1.220772  0.941183 -0.609113  0.104928 -0.783423  1.151730   \n",
       "4       -0.741355 -1.220772  0.941183 -0.588445  0.104928  0.753279  1.345611   \n",
       "...           ...       ...       ...       ...       ...       ...       ...   \n",
       "3141405 -0.660579  0.875537  0.421628 -0.428097 -0.075548 -0.533092 -0.193732   \n",
       "3141406 -0.670493  0.875537  0.421628 -0.729949 -1.514277  0.013145 -0.890270   \n",
       "3141407  0.820784 -1.142157  0.421628 -0.363329  1.363181 -0.079106 -1.580124   \n",
       "3141408  0.133074 -1.142157  0.421628 -0.375288 -1.514277 -0.973762  0.608647   \n",
       "3141409  3.271590  0.875537  0.421628 -0.170709  1.363181 -0.563314  0.669586   \n",
       "\n",
       "            f_299  \n",
       "0        0.321566  \n",
       "1       -0.343624  \n",
       "2        0.243608  \n",
       "3       -0.773309  \n",
       "4       -0.737624  \n",
       "...           ...  \n",
       "3141405 -0.581394  \n",
       "3141406 -0.589705  \n",
       "3141407 -0.297625  \n",
       "3141408 -0.372040  \n",
       "3141409  0.456400  \n",
       "\n",
       "[3141410 rows x 304 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739a67d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:02:37.299278Z",
     "start_time": "2022-04-07T13:02:26.556084Z"
    }
   },
   "outputs": [],
   "source": [
    "X_valid, X_train, y_valid, y_train = train_test_split(X_train, y_train, test_size=0.1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "904b86d9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:02:38.296155Z",
     "start_time": "2022-04-07T13:02:38.168825Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(pd.DataFrame(df[\"investment_id\"]))\n",
    "X_train[\"investment_id\"] = scaler.transform(pd.DataFrame(X_train[\"investment_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1238c804",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:04:33.877420Z",
     "start_time": "2022-04-07T13:04:33.772974Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(128, activation=\"swish\")(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(16, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f187f684",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:10:49.742824Z",
     "start_time": "2022-04-07T13:04:34.719898Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7854/7854 [==============================] - 74s 9ms/step - loss: 0.8518 - mae: 0.6344 - val_loss: 0.8242 - val_mae: 0.6216\n",
      "Epoch 2/5\n",
      "7854/7854 [==============================] - 76s 10ms/step - loss: 0.8338 - mae: 0.6262 - val_loss: 0.8202 - val_mae: 0.6235\n",
      "Epoch 3/5\n",
      "7854/7854 [==============================] - 74s 9ms/step - loss: 0.8302 - mae: 0.6249 - val_loss: 0.8191 - val_mae: 0.6196\n",
      "Epoch 4/5\n",
      "7854/7854 [==============================] - 75s 10ms/step - loss: 0.8268 - mae: 0.6237 - val_loss: 0.8184 - val_mae: 0.6217\n",
      "Epoch 5/5\n",
      "7854/7854 [==============================] - 75s 10ms/step - loss: 0.8235 - mae: 0.6228 - val_loss: 0.8226 - val_mae: 0.6258\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c3bf1bc0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:14:04.904675Z",
     "start_time": "2022-04-07T13:14:04.744220Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(64, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(256, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(512, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(256, activation=\"swish\")(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fec2ac90",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:20:38.559645Z",
     "start_time": "2022-04-07T13:14:10.191568Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7854/7854 [==============================] - 77s 10ms/step - loss: 0.8496 - mae: 0.6337 - val_loss: 0.8265 - val_mae: 0.6276\n",
      "Epoch 2/5\n",
      "7854/7854 [==============================] - 76s 10ms/step - loss: 0.8341 - mae: 0.6267 - val_loss: 0.8225 - val_mae: 0.6198\n",
      "Epoch 3/5\n",
      "7854/7854 [==============================] - 78s 10ms/step - loss: 0.8309 - mae: 0.6253 - val_loss: 0.8232 - val_mae: 0.6283\n",
      "Epoch 4/5\n",
      "7854/7854 [==============================] - 77s 10ms/step - loss: 0.8270 - mae: 0.6242 - val_loss: 0.8240 - val_mae: 0.6243\n",
      "Epoch 5/5\n",
      "7854/7854 [==============================] - 80s 10ms/step - loss: 0.8236 - mae: 0.6230 - val_loss: 0.8194 - val_mae: 0.6221\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "afbb3f17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:37:55.016910Z",
     "start_time": "2022-04-07T13:37:54.818682Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(32, activation=\"swish\")(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(256, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(512, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(512, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(256, activation=\"swish\")(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(32, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "Output = keras.layers.Dense(1, activation=\"linear\")(x)\n",
    "\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff2916eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:44:08.392818Z",
     "start_time": "2022-04-07T13:37:55.986812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7854/7854 [==============================] - 75s 9ms/step - loss: 0.8524 - mae: 0.6356 - val_loss: 0.8469 - val_mae: 0.6361\n",
      "Epoch 2/5\n",
      "7854/7854 [==============================] - 73s 9ms/step - loss: 0.8355 - mae: 0.6274 - val_loss: 0.8278 - val_mae: 0.6239\n",
      "Epoch 3/5\n",
      "7854/7854 [==============================] - 74s 9ms/step - loss: 0.8319 - mae: 0.6259 - val_loss: 0.8279 - val_mae: 0.6255\n",
      "Epoch 4/5\n",
      "7854/7854 [==============================] - 74s 9ms/step - loss: 0.8280 - mae: 0.6245 - val_loss: 0.8254 - val_mae: 0.6209\n",
      "Epoch 5/5\n",
      "7854/7854 [==============================] - 76s 10ms/step - loss: 0.8247 - mae: 0.6235 - val_loss: 0.8185 - val_mae: 0.6202\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e6e449e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T14:36:22.714890Z",
     "start_time": "2022-04-07T14:36:22.452956Z"
    }
   },
   "outputs": [],
   "source": [
    "Input = keras.layers.Input(shape=X_train.shape[1])\n",
    "x = keras.layers.Dense(32, activation=\"swish\")(Input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(64, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(128, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(256, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.layers.Dense(512, activation=\"swish\")(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "## convolution 1 ##\n",
    "feature_x = keras.layers.Reshape((-1,1))(x)\n",
    "feature_x = keras.layers.Conv1D(filters=16, kernel_size=2, strides=1, padding='same')(feature_x)\n",
    "feature_x = keras.layers.BatchNormalization()(feature_x)\n",
    "feature_x = keras.layers.LeakyReLU()(feature_x)\n",
    "## convolution 2 ##\n",
    "feature_x = keras.layers.Conv1D(filters=32, kernel_size=4, strides=1, padding='same')(feature_x)\n",
    "feature_x = keras.layers.BatchNormalization()(feature_x)\n",
    "feature_x = keras.layers.LeakyReLU()(feature_x)\n",
    "## convolution 3 ##\n",
    "feature_x = keras.layers.Conv1D(filters=64, kernel_size=8, strides=1, padding='same')(feature_x)\n",
    "feature_x = keras.layers.BatchNormalization()(feature_x)\n",
    "feature_x = keras.layers.LeakyReLU()(feature_x)\n",
    "## convolution 4 ##\n",
    "feature_x = keras.layers.Conv1D(filters=128, kernel_size=16, strides=1, padding='same')(feature_x)\n",
    "feature_x = keras.layers.BatchNormalization()(feature_x)\n",
    "feature_x = keras.layers.LeakyReLU()(feature_x)\n",
    "\n",
    "## flatten ##\n",
    "feature_x = keras.layers.Flatten()(feature_x)\n",
    "\n",
    "x = keras.layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(feature_x)\n",
    "\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "x = keras.layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "x = keras.layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "x = keras.layers.Dropout(0.1)(x)\n",
    "Output = keras.layers.Dense(1)(x)\n",
    "model = keras.models.Model(inputs = Input, outputs = Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6dcec68e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T15:09:41.570268Z",
     "start_time": "2022-04-07T14:36:23.627613Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7854/7854 [==============================] - 407s 51ms/step - loss: 1.6737 - mae: 0.6419 - val_loss: 0.9072 - val_mae: 0.6281\n",
      "Epoch 2/5\n",
      "7854/7854 [==============================] - 398s 51ms/step - loss: 0.8698 - mae: 0.6298 - val_loss: 0.8455 - val_mae: 0.6293\n",
      "Epoch 3/5\n",
      "7854/7854 [==============================] - 399s 51ms/step - loss: 0.8488 - mae: 0.6290 - val_loss: 0.8339 - val_mae: 0.6255\n",
      "Epoch 4/5\n",
      "7854/7854 [==============================] - 398s 51ms/step - loss: 0.8446 - mae: 0.6289 - val_loss: 0.8339 - val_mae: 0.6255\n",
      "Epoch 5/5\n",
      "7854/7854 [==============================] - 395s 50ms/step - loss: 0.8441 - mae: 0.6288 - val_loss: 0.8338 - val_mae: 0.6275\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics=[\"mae\"])\n",
    "history = model.fit(X_train, y_train, validation_split=0.2, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a81ac1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c1a31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf6026b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "=python3.9.0",
   "language": "python",
   "name": "python3.9.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2134.664216,
   "end_time": "2022-03-30T14:07:10.868727",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-03-30T13:31:36.204511",
   "version": "2.3.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "907.778px",
    "left": "68.9931px",
    "top": "180.002px",
    "width": "426.667px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "595.851px",
    "left": "1764.33px",
    "right": "20px",
    "top": "121px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
